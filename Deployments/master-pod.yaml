apiVersion: v1
kind: Pod
metadata:
  name: master
  labels:
    k8s-app: spark-torch
spec:
  # affinity:
  #  nodeAffinity:
  #    requiredDuringSchedulingIgnoredDuringExecution:
  #      nodeSelectorTerms:
  #      - matchExpressions:
  #        - key: nvidia.com/gpu.product
  #          operator: In
  #          values:
  #           - NVIDIA-GeForce-RTX-2080-Ti
  nodeSelector:
    topology.kubernetes.io/region: us-west
    topology.kubernetes.io/zone: fullerton
  volumes:
  - name: config-volume
    persistentVolumeClaim:
      claimName: shared-pvc
  initContainers:
  - name: init-dns
    image: busybox
    command: ["sh", "-c"]
    args:
      - "echo $(hostname -i)\tmaster >> /config/ips"
    volumeMounts:
    - name: config-volume
      mountPath: /config
  containers:
  - name: master
    image: "gitlab-registry.nrp-nautilus.io/focegueda/data-curator-and-model-dispatcher/sparktorchkafka:latest"
    resources:
      limits:
        memory: 24Gi
        cpu: 8000m
        nvidia.com/gpu: 1
      requests:
        memory: 24Gi
        cpu: 8000m
        nvidia.com/gpu: 1
    ports:
    - containerPort: 8088
      hostPort: 8088
      protocol: TCP
    - containerPort: 9864
      hostPort: 9864
      protocol: TCP
    - containerPort: 9000
      hostPort: 9000
      protocol: TCP
    - containerPort: 9870
      hostPort: 9870
      protocol: TCP
    - containerPort: 8042
      hostPort: 8042
      protocol: TCP
    - containerPort: 9868
      hostPort: 9868
      protocol: TCP
    - containerPort: 10020
      hostPort: 10020
      protocol: TCP
    - containerPort: 19888
      hostPort: 19888
      protocol: TCP
    - containerPort: 4040
      hostPort: 4040
      protocol: TCP
    - containerPort: 7077
      hostPort: 7077
      protocol: TCP
    - containerPort: 7078
      hostPort: 7078
      protocol: TCP
    - containerPort: 8080
      hostPort: 8080
      protocol: TCP
    - containerPort: 8081
      hostPort: 8081
      protocol: TCP
    - containerPort: 9092
      hostPort: 9092
      protocol: TCP
    - containerPort: 9093
      hostPort: 9093
      protocol: TCP
    volumeMounts:
    - name: config-volume
      mountPath: /config
    command: ["bash", "-c"]
    args: [
      "echo $(bash /usr/local/kafka/bin/kafka-storage.sh random-uuid) >> /config/uuid; \
       apt-get install unzip -y; \
       apt-get install zip -y; \
       apt-get install libxcb-xinerama0 -y; \
       apt install libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-xinerama0 libxcb-xkb1 libxkbcommon-x11-0 -y; \
       echo \"export QT_DEBUG_PLUGINS=1\" >> /root/.bashrc; \
       echo \"export QT_QPA_PLATFORM_PLUGIN_PATH=/usr/local/miniconda3/lib/python3.12/site-packages/PyQt5/Qt5/plugins/platforms\" >> /root/.bashrc; \
       echo \"export KAGGLE_USERNAME=\"; \
       echo \"export KAGGLE_KEY=\"; \
       echo \"SPARK_CLASSPATH=$(find /usr/local/spark/jars -name '*.jar' | tr '\n' ':')\" >> /root/.bashrc; \
       echo 'SPARK_WORKER_PORT=7078' >> /root/.bashrc; \
       echo 'SPARK_WORKER_OPTS=\"-Dspark.worker.resource.gpu.amount=1 -Dspark.worker.resource.gpu.discoveryScript=/opt/sparkRapidsPlugin/getGpusResources.sh\"' >> /usr/local/spark/conf/spark-env.sh; \
       echo 'SPARK_WORKER_OPTS=\"-Dspark.worker.resource.gpu.amount=1 -Dspark.worker.resource.gpu.discoveryScript=/opt/sparkRapidsPlugin/getGpusResources.sh\"' >> /root/.bashrc; \
       source /usr/local/miniconda3/bin/activate; \
       conda install -c conda-forge transformers -y; \
       conda install -c conda-forge diffusers -y; \
       conda install seaborn -y; \
       conda install matplotlib -y; \
       conda install scikit-learn -y; \
       conda install pyqt -y; \
       echo \"y\"| pip install pyqt5; \
       echo \"y\"| pip install kaggle; \
       conda install -c conda-forge pillow -y; \
       conda install -c conda-forge libxcb -y; \
       echo \"y\" | pip install torchsummary ; \
       mkdir -p /home/Codebase; \
       echo 'Reloading bashrc'; \
       . /root/.bashrc; \
       . /etc/profile; \
       /usr/sbin/sshd; \
       echo 'Checking for NVIDIA devices'; \
       if ls /dev | grep -q 'nvidia[0-9]*'; then \
         echo 'NVIDIA devices found!'; \
       else \
         echo 'NVIDIA devices not found'; \
       fi; \
       sleep 30; \
       echo 'Fetching node IPs and updating /etc/hosts'; \
       cat /config/ips >> /etc/hosts; \
       echo 'Updated /etc/hosts'; \
       sleep 15; \
       echo 'Starting Kafka Broker'; \
       export CURRENT_SERVER_INDEX=4; \
       export CLUSTER_UUID=$(cat /config/uuid); \
       sed -i \"s#node.id=.*#node.id=${CURRENT_SERVER_INDEX}#g\" /usr/local/kafka/config/kraft/server.properties; \
       sed -i \"s#controller.quorum.voters=.*#controller.quorum.voters=1@slave01:9093,2@slave02:9093,3@slave03:9093,4@master:9093#g\" /usr/local/kafka/config/kraft/server.properties; \
       sed -i \"s#log.dirs=.*#log.dirs=/var/kafka#g\" /usr/local/kafka/config/kraft/server.properties; \
       bash /usr/local/kafka/bin/kafka-storage.sh format -t ${CLUSTER_UUID} -c /usr/local/kafka/config/kraft/server.properties; \
       bash /usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/kraft/server.properties; \
       sleep 30; \
       echo 'Downloading Kaggle Dataset, Please Wait For This To Complete'; \
       mkdir -p /config/AI_Human_Generated_Images; \
       kaggle datasets download alessandrasala79/ai-vs-human-generated-dataset -p /config; \
       unzip /config/ai-vs-human-generated-dataset.zip -d /config/AI_Human_Generated_Images; \
       rm -rf /config/ai-vs-human-generated-dataset.zip; \
       echo 'Dataset Downloaded'; \
       chmod +x /opt/sparkRapidsPlugin/getGpusResources.sh; \
       ./usr/local/spark/sbin/start-all.sh --host master --port 7077; \
       sleep 30; \
       echo 'TRAINING'; \
       bash /config/Codebase/train.sh; \
       echo 'TRAINING HAS ENDED'; \
       tail -f /dev/null;
       "
    ]

##?###########################################?##
###? Use this snippet to start HDFS and YARN ?###
##?###########################################?##
      #  echo 'Starting HDFS and YARN'; \
      #  hdfs namenode -format -force -nonInteractive; \
      #  start-dfs.sh; \
      #  start-yarn.sh; \
      #  echo 'Setting Up Directories'; \
      #  hadoop fs -mkdir /sparklog; \
      #  hadoop fs -chmod 777 /sparklog; \
      #  hadoop fs -mkdir /user; \
      #  hadoop fs -chmod 777 /user; \
      #  hadoop fs -put /home/AI_Human_Generated_Images /user; \
      #  rm -rf /home/AI_Human_Generated_Images; \
      #  echo 'Directories Set Up'; \

##?###########################################?##
###? Use this snippet to start model trainer ?###
##?###########################################?##
      #  sleep 30; \
      #  echo 'TRAINING'; \
      #  bash /config/Codebase/train.sh; \
      #  echo 'TRAINING HAS ENDED'; \