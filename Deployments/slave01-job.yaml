apiVersion: batch/v1
kind: Job
metadata:
  name: slave01
  labels:
    k8s-app: spark-torch
spec:
  template:
    spec:
      nodeSelector:
        topology.kubernetes.io/region: us-west
        topology.kubernetes.io/zone: ucsd-nrp
      restartPolicy: Never
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                  - NVIDIA-A100-SXM4-80GB
      volumes:
      - name: config-volume
        persistentVolumeClaim:
          claimName: datasets-pvc
      - name: data-volume
        persistentVolumeClaim:
          claimName: datasets-pvc-2
      containers:
      - name: slave01
        image: "gitlab-registry.nrp-nautilus.io/focegueda/calm-vit-dte/sparktorchkafka:latest"
        resources:
          limits:
            memory: 64Gi
            cpu: 32000m
            nvidia.com/a100: 4
          requests:
            memory: 64Gi
            cpu: 32000m
            nvidia.com/a100: 4
        ports:
        - containerPort: 8088
          hostPort: 8088
          protocol: TCP
        - containerPort: 9864
          hostPort: 9864
          protocol: TCP
        - containerPort: 9000
          hostPort: 9000
          protocol: TCP
        - containerPort: 9870
          hostPort: 9870
          protocol: TCP
        - containerPort: 8042
          hostPort: 8042
          protocol: TCP
        - containerPort: 9868
          hostPort: 9868
          protocol: TCP
        - containerPort: 10020
          hostPort: 10020
          protocol: TCP
        - containerPort: 19888
          hostPort: 19888
          protocol: TCP
        - containerPort: 4040
          hostPort: 4040
          protocol: TCP
        - containerPort: 7077
          hostPort: 7077
          protocol: TCP
        - containerPort: 7078
          hostPort: 7078
          protocol: TCP
        - containerPort: 8080
          hostPort: 8080
          protocol: TCP
        - containerPort: 8081
          hostPort: 8081
          protocol: TCP
        - containerPort: 9092
          hostPort: 9092
          protocol: TCP
        - containerPort: 9093
          hostPort: 9093
          protocol: TCP
        - containerPort: 22
          hostPort: 22
          protocol: TCP
        volumeMounts:
        - name: config-volume
          mountPath: /config
        - name: data-volume
          mountPath: /dataset
        command: ["bash", "-c"]
        args: [
          "
          echo '0' > /config/state; \
          echo $(hostname -i)\t$(hostname) >> /config/ips_temp;\
          echo $(hostname) >> /config/workers_tmp; \
          apt-get install libxcb-xinerama0 -y; \
          apt install libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-xinerama0 libxcb-xkb1 libxkbcommon-x11-0 -y; \
          echo \"export QT_DEBUG_PLUGINS=1\" >> /root/.bashrc; \
          echo \"export QT_QPA_PLATFORM_PLUGIN_PATH=/usr/local/miniconda3/lib/python3.12/site-packages/PyQt5/Qt5/plugins/platforms\" >> /root/.bashrc; \
          echo \"SPARK_CLASSPATH=$(find /usr/local/spark/jars -name '*.jar' | tr '\n' ':')\" >> /root/.bashrc; \
          echo 'SPARK_WORKER_OPTS=\"-Dspark.worker.resource.gpu.amount=4 -Dspark.worker.resource.gpu.discoveryScript=/opt/sparkRapidsPlugin/getGpusResources.sh\"' >> /usr/local/spark/conf/spark-env.sh; \
          echo 'SPARK_WORKER_OPTS=\"-Dspark.worker.resource.gpu.amount=4 -Dspark.worker.resource.gpu.discoveryScript=/opt/sparkRapidsPlugin/getGpusResources.sh\"' >> /root/.bashrc; \
          source /usr/local/miniconda3/bin/activate; \
          conda install -c conda-forge transformers -y; \
          conda install -c conda-forge diffusers -y; \
          conda install seaborn -y; \
          conda install matplotlib -y; \
          conda install scikit-learn -y; \
          conda install pyqt -y; \
          echo \"y\"| pip install pyqt5 py4j memory-profiler pyspark scipy torch torchvision torchaudio torcheval deepspeed pyspark[sql] pyspark[pandas_on_spark] pyspark[ml] pyspark[mllib] matplotlib scikit-learn; \
          conda install -c conda-forge libxcb -y; \
          conda install -c conda-forge pillow -y; \
          echo \"y\" | pip install torchsummary; \
          echo 'Reloading bashrc'; \
          . /root/.bashrc; \
          . /etc/profile; \
          /usr/sbin/sshd; \
          echo 'Checking for NVIDIA devices'; \
          if ls /dev | grep -q 'nvidia[0-9]*'; then \
            echo 'NVIDIA devices found!'; \
          else \
            echo 'NVIDIA devices not found'; \
          fi; \
          sleep 15; \
          echo 'Fetching node IPs and updating /etc/hosts'; \
          cat /config/ips_temp > /config/ips; \
          cat /config/ips >> /etc/hosts; \
          cat /config/workers_tmp > /usr/local/spark/conf/workers; \
          chmod +x /opt/sparkRapidsPlugin/getGpusResources.sh; \
          echo 'Updated /etc/hosts'; \
          sleep 15; \
          echo 'Waiting for training to end.'; \
          until grep -q '1' /config/state; do \
              sleep 5; \
          done;
          "
        ]