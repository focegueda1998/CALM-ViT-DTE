apiVersion: v1
kind: Pod
metadata:
  name: slave01
  labels:
    k8s-app: hadoop
spec:
  # affinity:
  #   nodeAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       nodeSelectorTerms:
  #       - matchExpressions:
  #         - key: nvidia.com/gpu.product
  #           operator: In
  #           values:
  #           - NVIDIA-L4
  #           - NVIDIA-GeForce-RTX-3090
  # nodeSelector:
  #   topology.kubernetes.io/region: us-west
  #   topology.kubernetes.io/zone: fullerton
  nodeSelector:
    topology.kubernetes.io/region: us-central
    topology.kubernetes.io/zone: unl
  volumes:
  - name: config-volume
    persistentVolumeClaim:
      claimName: shared-pvc
  initContainers:
  - name: init-dns
    image: busybox
    command: ["sh", "-c"]
    args:
      - "echo $(hostname -i) > /config/slave01_ip"
    volumeMounts:
    - name: config-volume
      mountPath: /config
  containers:
  - name: slave01
    image: "gitlab-registry.nrp-nautilus.io/focegueda/data-curator-and-model-dispatcher/sparktorchkafka:latest"
    resources:
      limits:
        memory: 24Gi
        cpu: 10000m
        nvidia.com/gpu: 1
      requests:
        memory: 24Gi
        cpu: 10000m
        nvidia.com/gpu: 1
    ports:
    - containerPort: 8088
      hostPort: 8088
      protocol: TCP
    - containerPort: 9864
      hostPort: 9864
      protocol: TCP
    - containerPort: 9000
      hostPort: 9000
      protocol: TCP
    - containerPort: 9870
      hostPort: 9870
      protocol: TCP
    - containerPort: 8042
      hostPort: 8042
      protocol: TCP
    - containerPort: 9868
      hostPort: 9868
      protocol: TCP
    - containerPort: 10020
      hostPort: 10020
      protocol: TCP
    - containerPort: 19888
      hostPort: 19888
      protocol: TCP
    - containerPort: 4040
      hostPort: 4040
      protocol: TCP
    - containerPort: 7077
      hostPort: 7077
      protocol: TCP
    - containerPort: 7078
      hostPort: 7078
      protocol: TCP
    - containerPort: 8080
      hostPort: 8080
      protocol: TCP
    - containerPort: 8081
      hostPort: 8081
      protocol: TCP
    - containerPort: 9092
      hostPort: 9092
      protocol: TCP
    - containerPort: 9093
      hostPort: 9093
      protocol: TCP
    volumeMounts:
    - name: config-volume
      mountPath: /config
    command: ["bash", "-c"]
    args: [
      "apt-get install libxcb-xinerama0 -y; \
       apt install libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-xinerama0 libxcb-xkb1 libxkbcommon-x11-0 -y; \
       echo \"export QT_DEBUG_PLUGINS=1\" >> /root/.bashrc; \
       echo \"export QT_QPA_PLATFORM_PLUGIN_PATH=/usr/local/miniconda3/lib/python3.12/site-packages/PyQt5/Qt5/plugins/platforms\" >> /root/.bashrc; \
       echo \"SPARK_CLASSPATH=$(find /usr/local/spark/jars -name '*.jar' | tr '\n' ':')\" >> /root/.bashrc; \
       source /usr/local/miniconda3/bin/activate; \
       conda install -c conda-forge transformers -y; \
       conda install -c conda-forge diffusers -y; \
       conda install seaborn -y; \
       conda install matplotlib -y; \
       conda install scikit-learn -y; \
       conda install pyqt -y; \
       echo \"y\"| pip install pyqt5; \
       conda install -c conda-forge libxcb -y; \
       conda install -c conda-forge pillow -y; \
       echo \"y\" | pip install torchsummary; \
       echo 'Reloading bashrc'; \
       . /root/.bashrc; \
       . /etc/profile; \
       /usr/sbin/sshd; \
       echo 'Checking for NVIDIA devices'; \
       if ls /dev | grep -q 'nvidia[0-9]*'; then \
         echo 'NVIDIA devices found, appending configuration to container-executor.cfg'; \
         echo '[docker]' >> $HADOOP_HOME/etc/hadoop/container-executor.cfg; \
          echo \"docker.allowed.devices=/dev/nvidia-uvm,/dev/nvidia-uvm-tools,$(ls /dev | grep 'nvidia[0-9]*' | tr '\n' ',' | sed 's/,$//'),/dev/nvidiactl\" >> $HADOOP_HOME/etc/hadoop/container-executor.cfg; \
         echo 'docker.allowed.ro-mounts=nvidia_driver_550.127.05' >> $HADOOP_HOME/etc/hadoop/container-executor.cfg; \
         echo 'docker.allowed.runtimes=nvidia' >> $HADOOP_HOME/etc/hadoop/container-executor.cfg; \
       else \
         echo 'NVIDIA devices not found'; \
       fi; \
       sleep 30; \
       echo 'Fetching node IPs and updating /etc/hosts'; \
       export MASTER_IP=$(cat /config/master_ip); \
       export SLAVE02_IP=$(cat /config/slave02_ip); \
       export SLAVE03_IP=$(cat /config/slave03_ip); \
       echo $MASTER_IP master >> /etc/hosts; \
       echo $SLAVE02_IP slave02 >> /etc/hosts; \
       echo $SLAVE03_IP slave03 >> /etc/hosts; \
       chmod +x /opt/sparkRapidsPlugin/getGpusResources.sh; \
       echo 'Updated /etc/hosts'; \
       sleep 15; \
       echo 'Setting up Kafka Controller'; \
       export CURRENT_SERVER_INDEX=1; \
       export CLUSTER_UUID=$(cat /config/uuid); \
       sed -i \"s#node.id=.*#node.id=${CURRENT_SERVER_INDEX}#g\" /usr/local/kafka/config/kraft/server.properties; \
       sed -i \"s#controller.quorum.voters=.*#controller.quorum.voters=1@slave01:9093,2@slave02:9093,3@slave03:9093,4@master:9093#g\" /usr/local/kafka/config/kraft/server.properties; \
       sed -i \"s#log.dirs=.*#log.dirs=/var/kafka#g\" /usr/local/kafka/config/kraft/server.properties; \
       bash /usr/local/kafka/bin/kafka-storage.sh format -t ${CLUSTER_UUID} -c /usr/local/kafka/config/kraft/server.properties; \
       bash /usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/kraft/server.properties; \
       echo 'awaiting for master to start'; \
       tail -f /dev/null; "
    ]